# 6. Relational DB Design
## F+ 계산절차
```
 F⁺ = F
 repeat
   for each functional dependency f in F⁺
     apply reflexivity and augmentation rules on f
     add the resulting functional dependencies to F⁺
   for each pair of functional dependencies f1 and f2 in F⁺
     if f1 and f2 can be combined using transitivity
       then add the resulting functional dependency to F⁺
 until F + does not change any further
```
reflexivity(반사성)와 augmentation(증강)을 f에 적용해 더 많은 functional dependencies를 적용하고 나온 결과를 $F^+$에 추가한다.<br>
$F^+$안에 있는 두 쌍에 대해 transitivity가 가능한지 확인하고 가능하면 결과를 $F^+$에 추가한다.<br>
최악의 경우 O($2^n$) 의 F개수 만큼
- Reflexivity: A → A (자기 자신을 함수로)  /  Augmentation: 양쪽에 같은 속성 추가 A → B이면 AC → BC

## Closure of Functional Dependencies
- α → β이고, α → γ라면, α → βγ도 성립한다 (union)
- α → βγ가 성립하면, α → β도 성립하고 α → γ도 성립한다 (decomposition)
- α → β이고, γβ → δ라면, αγ → δ도 성립한다 (pseudotransitivity)

## Closure of Attribute Sets
- set of attributes(속성 집합) α가 주어졌을 때, F에 대한 closure of α(α⁺)를, F에 의해 α로부터 함수적으로 결정되는 속성들의 집합으로 정의한다.
``` 
result := α;
 while (changes to result) do
 for each β → γ in F do
 begin
 if β ⊆ result then result := result ∪ γ
end
```
α → result 이고 β → γ 일때 if부분 만족시 result → β 이므로 α → γ 이다.

### Example of Attribute Set Closure
- R = (A, B, C, G, H, I)  /  F = {A → B, A → C, CG → H, CG → I, B → H}
- $(AG)^+$ 주어진 함수적 종속성 집합 F 아래에서 (AG)⁺를 계산한 결과:
1. result = AG
2. A → B, A → C 사용 → result = ABCG
3. CG → H 사용 가능 (CG ⊆ ABCG) → result = ABCGH
4. CG → I 사용 가능 (CG ⊆ ABCGH) → result = ABCGHI <br>
최종적으로 (AG)⁺ = {A, B, C, G, H, I} AG에서 모든것으로 갈 수 있으므로 superkey이다.
- AG는 cadidate key인가?
  - $A^+$에 대해
  1. result = $A^+$
  2. result = ABC
  3. result = ABCH -> A는 keyX
  - $G^+$에 대해
  1. result = G -> G도 keyX <br>
따라서 $AG^+$는 cadidate key이다.

## Uses of Attribute Closure
there are several uses of the attribute closure algorithm:
- Testing for Superkey:<br>
  α가 슈퍼키인지 확인하려면, α⁺를 계산하고 R(릴레이션의 모든 속성)을 포함하는지 확인한다.
- Testing Functional Dependencies:<br>
  함수적 종속성 α → β가 성립하는지(F⁺에 포함되는지) 확인하려면, α⁺를 구해서 β가 그 안에 포함되는지 확인하면 된다. 
- Computing Closure of F (F⁺ 구하기) :<br>
  $F^+$를 다 구해서 Union을 통해 구할 수 있다.

## Lossless-join Decomposition
- R = (R₁, R₂)로 쪼갠 후,  각각 쪼갠것을 join하면 R로 원상복구 가능
- R을 R₁과 R₂로 decomposition한 것이 lossless join이 되려면, 다음 종속성들 중 적어도 하나가 F⁺에 포함되어 있어야 한다:
  - R₁ ∩ R₂ → R₁
  - R₁ ∩ R₂ → R₂ <br>

따라서, R₁과 R₂의 교집합이 R₁ 또는 R₂ 중 적어도 하나의 슈퍼키(superkey)를 이루면, R의 decomposition는 lossless decomposition이다.
- 참고사항 : <br>
  R = (A,B,C) -> attribute 집합 / r(A,B,C) -> relation

### Example
- R = (A, B, C) <br>
F = {A → B, B → C) A가 key이다. <br>

2가지 다른 방법으로 쪼갤 수 있다.
1. R1 = (A, B),   R2 = (B, C)
- Lossless-join decomposition : R1 ∩ R2 = {B} and B → BC 이므로 R1 ∩ R2 = R2(={BC})이다. <br>
따라서 Dependency preserving
2. R1 = (A, B),   R2 = (A, C)
- Lossless-join decomposition : R1 ∩ R2 = {A} and A → AB R1 ∩ R2 = R1(={AB})이다. <br>
하지만 Not dependency preserving B -> C를 바로 확인 불가능하기 때문

## Dependency Preservation
Fᵢ는 F⁺중에서 Rᵢ에 포함된 attributes만 사용하는 set of dependencies이다.
- 다음 조건이 만족되면 그 분해는 함수적 종속성 보존(dependency preserving)이라 한다: <br>
(F₁ ∪ F₂ ∪ … ∪ Fₙ)⁺ = F⁺
- 이 조건이 만족되지 않으면, 함수적 종속성 위반 여부를 검사하려면 relation들을 join해야 하며, 이는 비용이 많이 든다.

### Example
- R = (A, B, C),  F = {A → B, B →C} -> Key = {A} <br>
R is not in BCNF : B는 후보 키가 아닌데 결정자여서 -> BCNF 위반
- Decomposition R1 = (A, B),  R2 = (B, C) <br>
R1 and R2 in BCNF <br>
Lossless-join decomposition: 분해한 $R_1$과 $𝑅_2$ 를 다시 결합해도 원래의 𝑅을 완전히 복원할 수 있다.<br>
Dependency preserving: 원래 릴레이션에서의 모든 함수 종속성을 분해 후에도 각각의 분해 릴레이션에서 그대로 표현할 수 있다.

## BCNF and Dependency Preservation
항상 BCNF decomposition가 Dependency Preservation을 만족하는 것은 아니다.
- R = (J, K, L) / F = {JK → L, L → K}  candidate key는 JK와 JL 두 개 <br>
R은 BCNF를 만족하지 않는다 <br>
- 이유 : L → K는 BCNF 위반 (L은 슈퍼키가 아님, non trivaial) <br>
단, k는 cadidate key의 일부이므로 3NF 가능 -> 따라서 decompose할 필요가 없다.

## Comparison of BCNF and 3NF
- 3NF의 경우:
  - 항상 어떤 릴레이션이든 3NF로 분해할 수 있다.
  - decomposition lossless가 가능하고
  - 모든 dependencies preserved 할 수 있다.
- BCNF의 경우:
  - 모든 릴레이션을 BCNF로 분해하는 것은 가능하지만
  - decomposition lossless는 가능해도
  - preserve dependencies가 항상 가능한 것은 아니다

## Design Goals
- Goal for a relational database design is:
  - BCNF  /  Lossless join  /  Dependency preservation
- If we cannot achieve this, we accept one of(하나만 선택)
  - Lack of dependency preservation
  - Redundancy due to use of 3NF
-SQL은 슈퍼키(superkey) 이외의 다른 함수적 종속성을 직접적으로 명시하는 방법을 제공하지 않는다.<br>
함수적 종속성(FD)은 ASSERTION을 사용해서 명시할 수 있지만, 테스트 비용이 매우 크며, 현재 널리 사용되는 데이터베이스 시스템들에서는 지원되지 않는다!
- dependency preserving 분해를 했더라도,
SQL에서는 좌변이 키가 아닌 함수적 종속성을 효율적으로 검사할 수 없다. <br>
따라서 BCNF로 쪼개는게 더 좋다.

----------------------------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------------------------

# 7. Storage and File Structures
## 물리적 저장 매체
- Cache: 가장 빠르고 가장 비싼 형태의 storage
  - 휘발성, HW가 관리, 접근 시간: a few nanoseconds ( $10^{-9}$ seconds)
- Main memory (RAM)
  - 휘발성, 접근 시간: a few hundreds nanoseconds ( $10^{-7}$ seconds)
- Flash memory
  – 비휘발성, 접근 시간: under a hundred microseconds ( $10^{-4}$ ~ $10^{-5}$ seconds)
- Magnetic-disk
  - 비휘발성, 접근시간: a few milliseconds ( $10^{-3}$ seconds)
  - 데이터를 접근하려면 디스크에서 메인 메모리로 옮겨야 하며, 저장하려면 다시 디스크에 써야 한다.

## File Organization
- The database -> 각 files들의 모음 / 각 file -> records들의 순서로 구성 / record -> fields들의 순서로 구성
  - 각 file은 fixed-length storage units인 blocks으로 분할 (block은 저장 할당과 데이터 전송의 단위이고, 하나의 block에 여러 record 가능)
- Each file은 한 가지 유형의 records만 포함하고, 다른 relations는 다른 files에 저장된다.
- records 2가지 유형
  - Fixed-length records(고정 길이 레코드)
  - Variable-length records(가변 길이 레코드)
   
## External-Memory Model
- EM Model은 RAM (main memory) model과 다르다.
  - Time Complexity in RAM model: O(#basic operations) (e.g., memory access)
  - I/O Complexity in EM model: I/O: O(#I/O’s (read and write)) <br>
 Linear I/O: O( $N \over B$ ) < O(N)
- 일반적으로 사용되는 표기
  - N: data file에 있는 record의 수
  - M: main memory에 들어갈 수 있는 record의 수
  - B: 하나의 block에 들어갈 수 있는 record의 수

## Fixed-Length Records
 ID            char(5),       -> 5 bytes <br>
 name          varchar(20),   -> 20 bytes at most <br>
 dept_name     varchar(20),   -> 20 bytes at most <br>
 salary        numeric(8,2),  -> 8 bytes <br>
총 53byte fixed length이다.
- Simple approach:
  - 각 record i는 byte n * (i– 1)위치 부터 저장하기 시작한다. (n은 record의 크기이다)
  - Record 접근은 간단하지만, records가 block boundaries넘지 않게 가정을 해야한다.
- record i 삭제:
  - (단순한 방법): i+1 부터 n까지 모든 레코드를 i부터 n-1까지 앞으로 이동한다. <br>
  밑에거 부터 채우고, 채워지면 제자리로간다. 이런식으로 전부 진행하면서 채운다. -> O( $N \over B$ )I/O
  - (개선 방법): record n을 i로 이동시킨 후 삭제한다. <br>

![image](https://github.com/user-attachments/assets/6c2b322a-df9f-4093-8feb-502f308053b2)

## Maintaining Free Lists(삭제시 채우기보다는 그냥 비워두는 방법)
- file header에 첫 번째로 삭제된 record의 주소를 저장한다.
- 이 first record에 second deleted record의 주소를 저장, 이런식으로 계속 연결한다.
- 이러한 stored addresses를 pointers로 생각할 수 있는데, 이는 record의 위치를 가리키기 때문이다<br>
![image](https://github.com/user-attachments/assets/d9807fd0-8488-4780-bd98-ed3acdea0089) 
![image](https://github.com/user-attachments/assets/c8916881-42bd-45a8-9fa3-d9a7674b6db6)

## Variable-Length Records
- Variable-length records를 사용하는 경우:
  - 하나의 file에 multiple record types을 저장하는 경우
  - one or more fields(예: 문자열 varchar)의 길이가 variable lengths인 Record types
  - repeating fields(배열이나 멀티셋)를 허용하는 Record types <br>
- 가변 길이 레코드를 표현하는 방법
  - Two parts: fixed length attributes이 있는 initial part과 variable length attributes부분에는 데이터가 있다.
  - variable length attribute는 (offset, length)로 고정 크기 영역에 메타데이터를 저장하고, 실제 값은 레코드 뒤쪽에 따로 저장한다
  - Null 값은 null-value 비트맵으로 표현된다 <br>

![image](https://github.com/user-attachments/assets/d5ddf809-8058-4b32-b70d-432e3c59c031)

## Variable-Length Records: Slotted Page Structure
- 여러 개의 variable-length records를 하나의 블록에 저장하는 방법:
- slotted page header에는 다음 정보가 포함됨:
  - 레코드 항목의 개수
  - 블록 내의 남은 공간(free space)의 끝 위치
  - 각 레코드의 위치와 크기
- Records는 페이지 내에서 연속되도록 빈 공간 없이 이동시킬 수 있으며, 이때 entry in the header가 업데이트되어야 한다.
- Pointers는 record를 직접 가리키지 않고, 대신 header에 있는 해당 레코드의 항목(entry)을 가리켜야 한다. <br>

![image](https://github.com/user-attachments/assets/9ba949e8-9492-4b6f-a66f-8c0aa3b356e3)

## Organization of Records in Files
- 파일에 set of records를 배치하는 방법:
- 힙(Heap): 레코드는 파일 내의 빈 공간 어디든지 저장될 수 있다. -> 제일 많이 쓴다. 공간있고, 정책X, file도 heap file존재, record 넣을때 비워있으면 넣는다.
- 순차(Sequential): 각 레코드의 search key 값에 따라 순차적으로 정렬하여 저장한다. -> 이어 붙이기 + 정렬(pk가 기준)
- 해싱(Hashing): 레코드의 특정 속성에 대해 해시 함수를 계산하고, 그 결과에 따라 레코드를 저장할 블록이 결정된다. -> 정렬O -> binarysearch로 좀더 빠르게

## Sequential File Organization
- 전체 파일을 순차적(sequential)으로 처리해야 하는 응용 프로그램에 적합하다
- The records in the file은 search-key에 따라 정렬되어 있다 <br>

![image](https://github.com/user-attachments/assets/5f839dc9-7fdc-4cba-ac9c-97d438ad033c) <br>
- Deletion: 포인터 체인(pointer chain)을 사용하여 처리한다.
- Insertion: 레코드를 삽입할 위치를 찾는다.
  - 빈 공간이 있다면 그 자리에 삽입
  - 빈 공간이 없다면 오버플로우 블록(overflow block)에 삽입
  - 어떤 경우든 포인터 체인(pointer chain)을 업데이트해야 한다
- sequential order를 restore하기 위해 file을 주기적으로 재구성(reorganize)해야 한다.

## Storage Access
- database file은 block이라 불리는 fixed-length storage units로 분할(partitioned)된다.<br>
  block은 저장 할당(storage allocation)과 데이터 전송(data transfer)의 단위(units)이다.
- 데이터베이스 시스템은 disk와 memory 간의 block 전송 수를 최소화하려고 한다.<br>
  디스크 접근 횟수(the number of disk accesses)를 줄이기 위해, 가능한 많은 블록을 main memory에 유지한다.
- Buffer: disk blocks의 복사본을 저장하기 위해 사용되는 main memory의 일부 공간이다.
- Buffer manager: main memory 내에서 버퍼 공간을 할당하는 역할을 하는 하위 시스템(subsystem)이다.

## Buffer Manager
- program이 disk에서 block이 필요할 때 buffer manager를 호출한다.
1. 블록이 이미 버퍼에 존재하면, 버퍼 관리자는 returns the address of the block in main memory.
2. 블록이 버퍼에 없으면, 버퍼 관리자는 다음을 수행한다:
   1. 해당 블록을 위한 버퍼 공간을 할당한다
      1. 공간이 부족할 경우, 다른 블록을 교체(버림)하여 새 블록이 들어갈 자리를 만든다.
      2. 교체되는 블록은 수정된 경우에만 디스크에 다시 기록된다 (가장 최근의 읽기/쓰기 이후 변경되었을 때만).
   2. 디스크에서 블록을 읽어와 버퍼에 저장한 후, 요청자(requester)에게 returns the address of the block in main memory.

## Buffer-Replacement Policies
- 대부분의 OS는 Least Recently Used(LRU)을 교체하는 전략을 사용한다.
- LRU의 기본 아이디어: 과거의 블록 참조 패턴을 미래의 참조 패턴에 대한 예측으로 활용한다.
- 데이터베이스 쿼리는 명확한 접근 패턴(access patterns)(such as sequential scans)을 가지므로, DBMS는 쿼리 정보를 이용해 미래의 참조를 예측할 수 있다.
  - LRU는 데이터를 반복적으로 스캔하는 특정 접근 패턴에서는 비효율적일 수 있다. -> 두 릴레이션 중첩 조인
  - 따라서 query optimizer가 교체 전략에 대한 힌트를 제공하는 mixed strategy가 더 바람직하다.
- 최신 사용(MRU: Most Recently Used) 전략
  - 시스템은 현재 처리 중인 블록을 pin 한다.<br>
  해당 블록의 마지막 튜플까지 처리하면 블록의 unpinned되고, 이 블록은 가장 최근에 사용된 블록(most recently used block)이 된다.
    - pinned block: 디스크로 다시 쓰여서는 안 되는 메모리 블록이다.
- Buffer manager는 particular relation이 참조될 확률에 관한 통계 정보를 활용할 수 있다.
  - 예: 데이터 사전(data dictionary)은 자주 접근된다. Heuristic: data dictionary blocks은 main memory buffer에 유지한다. 

-------------------------------------------------------------------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------------------------------------------------------------------

# 8. indexing
## Motivation
- databases에서의 index: 찾고자 하는 records를 빠르게 찾기 위해 설계된 data structure이다.
  - 왜 그렇게 많은 종류의 인덱스가 존재하는가? -> 다양한 data types과 queries때문
- index가 필요한 이유는?
  - sql query를 효율적으로 수행하기 위해서

## Basic Concepts
- 원하는 data에 대한 접근을 빠르게 하기 위해 사용되는 indexsing mechanisms
- Search Key: file에서 records를 찾기 위해 사용되는 하나 이상의 attribute
- index file은 다음 형태의 records(index entries라고 부름)로 구성된다.<br>
  ![image](https://github.com/user-attachments/assets/8aff93f6-a41b-4036-985f-a4cacb5cc985)<br>
- Index files은 일반적으로 original file보다 작다.
- indices의 2가지 기본 종류:
  - Ordered indices(순차 인덱스): search keys가 정렬된 순서로 저장된다.
  - Hash indices(해시 인덱스): search keys가 hash function을 사용하여 buckets에 균등하게 분배된다.

## Index Evaluation Metrics (DB 인덱스 성능 평가 주요 지표)
- 효율적으로 지원되는 접근 유형
  - 특정 속성 값과 일치하는 레코드들 -> name = 'Alice'인 것을 빠르게 찾을 수 있는가?
  - 또는 속성 값이 특정 범위 내에 포함되는 레코드들 -> age가 20 ~ 30사이인 값을 빠르게 찾을 수 있는가?
- Access time -> 찾는데 걸리는 시간
- Insertion time -> 삽입하는데 걸리는 시간
- Deletion time -> 삭제하는데 걸리는 시간
- Space overhead -> 추가적으로 공간이 필요하지 않은지? <br>

![image](https://github.com/user-attachments/assets/8a486c04-4d8f-44e7-875d-338b4e590e5b)

## Ordered Indices
- ordered index: index entries가 search key value에 따라 정렬된 상태로 저장 
- primary index(=clustering index): 순차적으로 정렬된 파일에서, search key가 file의 정렬 순서를 지정하는 index
  - search key가 반드시 primary key가 아니다
- secondary(보조) index(=non-clustering index): search key가 파일의 sequential 정렬 순서(data 정렬순서)와 다른 순서를 지정하는 index이다.<br>
- index-sequential file: primary index를 갖는 정렬된 순차 파일

## Dense Index Files(index 구분 속성 dense VS sparse)
- Dense index: file에 존재하는 모든 search-key value마다 Index record가 존재하는 index.<br>
전부 같이 존재해서 밀도가 높다.
- Dense index on dept_name, with instructor file sorted on dept_name<br>
![image](https://github.com/user-attachments/assets/04433090-5e83-4f9f-9339-de499060a129) <br>
다만 dense index수가 record와 같을 필요는 없는데 그 이유는 중복이 될수고 있기 때문이다.

## Sparse Index Files(반드시 primary index이다)
- Sparse Index: 일부 search-key values에 대해서만 인덱스 records를 포함하는 index
  - search-key를 기준으로 records가 순차적으로 정렬되어 있을 때 적용 가능
- search-key value K를 가진 records를 찾기 위해서는:
  - K보다 작으면서 가장 큰 search-key value을 가진 index record를 찾고
  - 해당 인덱스 레코드가 가리키는 레코드부터 파일을 순차적으로 검색한다<br>
  
![image](https://github.com/user-attachments/assets/e74dedcb-435a-4769-81ac-053deba5a8b8)<br>
- dense indices와 비교:
  - 공간을 덜 차지, 삽입 및 삭제 시 유지 관리 비용이 더 적다.
  - 레코드를 찾는 속도는 dense index보다 느리다.
 - 절충안: 파일의 각 블록마다, 해당 블록에서의 가장 작은 search-key value에 대응하는
   인덱스 항목을 하나씩 갖는 sparse index.<br>
![image](https://github.com/user-attachments/assets/89366540-9434-4e3b-a3d2-9cafe3c0dcf6)<br>

## Multilevel Index
- primary(기본) index가 메모리에 모두 들어가지 않으면, 접근 비용이 많이 든다.
- Solution: 디스크에 저장된 primary index를 sequential file로 보고, 그 위에 sparse index를 생성한다.
  - outer index: primary index의 sparse index
  - inner index: primary index file
- 만약 외부 인덱스조차 메인 메모리에 들어가지 않을 정도로 크다면, 또 하나의 인덱스 레벨을 만들어야 한다.
- 모든 레벨의 인덱스는 파일에 삽입(insert) 또는 삭제(delete)가 발생할 때마다 함께 업데이트되어야 한다<br>
![image](https://github.com/user-attachments/assets/3cd4fa88-daef-4545-8bc6-93b7fdc59db5) <br>
![image](https://github.com/user-attachments/assets/861b5780-b99d-42f2-8f34-2f24ec76d0b2) <br>
![image](https://github.com/user-attachments/assets/abc717b8-9aaa-403a-a3a0-cf0a6ddd2fc5) <br>
즉, index의 index를 만드는 mutil index구조이다. <br>

![image](https://github.com/user-attachments/assets/b0454c03-e7c6-4725-a18a-81e5d1a1777a)<br>
![image](https://github.com/user-attachments/assets/c53cfacb-30d7-47ad-a8a5-3e350441aee3)

## Index Update: Deletion
- 삭제된 record가 해당 search-key value를 가진 file 내 유일한 record였다면, 그 검색 키도 index에서 삭제된다.
- Single-level index entry deletion:
  - Dense indices: search-key 삭제는 file record deletion과 유사하다.
  - Sparse indices
    - index에 해당 search key 항목이 존재하면, 그 항목은 파일 내 next search-key value(in search key order)으로 대체하여 삭제한다.<br>
    예로 D -> (4 D,5 E,6 F)일떄 D를 삭제한다면 E -> (5 E, 6 F)가 된다.
    - 만약 next search-key value이 이미 인덱스 항목으로 존재한다면, 대체하지 않고 해당 항목을 삭제한다. <br>
    예로 D -> (4, D) E -> (5 E, 6 F) 이고, D와 E가 각각 특정 부분을 대표하는 경우일때 그냥 D만 삭제한다. <br>
- 삭제 반복으로 인한 block에 빈 공간 생성 <br>
![image](https://github.com/user-attachments/assets/c779aec2-3e59-47fb-b331-5df5bf9d647b)<br>
DB 인덱스(혹은 데이터) 블록 관리에서 삭제가 반복되면 블록에 빈 공간이 생긴다. <br>
삽입 시 기존 블록의 빈 공간을 활용하지 않고 새 블록을 만드는 경우, 전체적으로 공간이 낭비된다. <br>
그래서 극단적인 경우로 1개씩만 있는 경우는 전체의 개수가 줄지않게 되는 문제가 발생한다. -> 공간 비효율 <br>
따라서 어느 정도 블록을 채우는 정책(예: fill factor 등)을 적용해야 하며, 그렇지 않으면 DB의 저장 효율이 크게 저하됩니다.

## Index Update: Insertion
- Single-level index insertion:
  - 삽입할 record에 나타나는 search-key value을 사용하여 조회를 수행한다.
  - Dense indices: 검색 키 값이 인덱스에 없다면 삽입한다.
  - Sparse indices: 인덱스가 파일의 각 블록에 대한 항목만 저장한다면, 새로운 블록이 생성되지 않는 한 인덱스에 변경을 가할 필요가 없다.
    - 새로운 블록이 생성되면, 해당 블록에 처음 나타나는 검색 키 값을 인덱스에 삽입한다.
- Multilevel insertion and deletion: 알고리즘은 단일 수준 알고리즘의 단순한 확장이다.

## Secondary Indices
- 흔히 어떤 field(기본 인덱스의 search-key가 아닌)의 value가 특정 조건을 만족하는 모든 record를 찾고자 하는 경우가 있다.
  - Ex) ID 기준으로 순차적으로 저장된 instructor 릴레이션에서, 특정 학과에 속한 모든 교수를 찾고자 할 수 있다.
- 이러한 경우, 각 search-key value에 대해 index record를 가지는 secondary(보조) index를 사용할 수 있다. <br>

## Secondary Indices Example
![image](https://github.com/user-attachments/assets/0a6111d0-4b61-4e77-bee1-067074db0813) <br>
- Index record는 해당 search-key value를 가진 실제 records를 모두 가리키는 pointers가 들어 있는 bucket을 가리킨다.
- secondary index는 반드시 dense index여야 한다.

## Primary and Secondary Indices
- index는 record를 검색할 때 상당한 이점을 제공한다.
- BUT: Updating indices은 데이터베이스 수정 시 오버헤드를 초래한다 —> 파일이 수정되면, 그 파일에 존재하는 모든 인덱스를 갱신해야 한다.
- primary index를 사용한 Sequential scan은 효율적이지만, secondary index를 사용한 sequential scan은 비용이 많이 든다.
  - 각 record를 접근할 때마다 disk에서 new block을 가져와야 할 수 있다.
  - block을 가져오는 데는 약 5~10밀리초가 걸리며, 이는 메모리 접근 시간인 약 100나노초에 비해 훨씬 느리다.
- 정렬을 시킨다. -> cost: $O\left(\frac{N}{B} \log_{\frac{N}{B}} \frac{N}{B}\right)$ - O(N) I/O's 보다 작다.

## $B^+$-Tree Index Files
- $B^+$-tree indices는 indexed-sequential files의 대안이다.
  - indexed-sequential files의 단점
    - file이 커질수록 많은 overflow block이 생성되어 performance가 저하된다.
    - 전체 파일을 주기적으로 재구성(reorganization)해야 한다.
  - $B^+$-tree indices 파일의 장점:
    - 변화가 있는 부분만 자동으로 재구성(reorganization)한다.
  - $B^+$-트리의 단점:
    - 삽입 및 삭제에 추가적인 overhead와 공간 overhead가 있다.
  - $B^+$-트리의 장점이 단점보다 크며, 널리 사용되고 있다.
   
## Example of $B^+$-Tree(dense, sparse 다 가능하다)
![image](https://github.com/user-attachments/assets/14840478-5261-429e-8ffe-65b7568b87c7) <br>
![image](https://github.com/user-attachments/assets/347be7ba-d695-4835-bb8f-877602490b7f) <br>
![image](https://github.com/user-attachments/assets/9983d4ca-7b14-4322-86ca-942c20f817a4)

## $B^+$-Tree Index Files (Cont.) 
- root에서 leaf까지 모든 paths의 length가 같다.
- root나 leaf가 아닌 node는 children의 수가 $\left\lceil \frac{n}{2} \right\rceil$ 이상 n 이하이다.
- leaf node는 값의 개수가 $\left\lceil \frac{(n-1)}{2} \right\rceil$ 이상 n–1 이하이다.
- Special 경우:
  - root가 leaf가 아니면, 최소 2개의 children을 가진다.
  - root가 leaf인 경우, 0개에서 (n–1)개의 값을 가질 수 있다.

## $B^+$-Tree Node Structure
- 일반적인 노드 <br>
  ![image](https://github.com/user-attachments/assets/5acda8ab-ed65-4546-8fb8-3d50b9116954) <br>
  - $K_i$는 search-key values이다.
  - $P_i$는 자식 노드를 가리키는 포인터(non-leaf nodes의 경우)이거나 leaf node에서는 실제 데이터(buckets)의 위치를 가리키는 pointers이다.
- 노드 내의 검색 키들은 $K_1 < K_2 < K_3 < \dots < K_{n-1}$ 순서로 정렬되어 있다.

## Leaf Nodes in $B^+$-Trees
leaf node의 특성:
- $i = 1, 2, \dots, n-1$에 대해, pointer $P_i$는 search-key value이 $K_i$인 file record를 가리킨다.
- 만약 $L_i$, $L_j$가 leaf nodes이고 $i < j$라면, $L_i$의 검색 키 값들은 $L_j$의 search-key values보다 작거나 같다.
- $P_n$은 search-key order에서 next leaf node를 가리킨다. <br>

![image](https://github.com/user-attachments/assets/2d675031-c2c2-4ac6-a2b1-03df5289e2ae)

## Non Leaf Nodes in $B^+$-Trees
- Non leaf nodes는 leaf nodes에 대한 multi-level sparse index를 형성한다. <br>
  non-leaf node에 pointers가 m개 있을 때:
  - $P_1$이 가리키는 subtree의 모든 search-keys 값은 $K_1$보다 작다.
  - $2 \leq i \leq n-1$인 경우, $P_i$가 가리키는 subtree의 모든 search-keys 값은 $K_{i-1}$ 이상이고 $K_i$ 미만이다.
  - $P_n$이 가리키는 서브트리의 모든 검색 키 값은 $K_{n-1}$ 이상이다. <br>

![image](https://github.com/user-attachments/assets/1a7dc67e-3f37-455a-b8c2-8ab6d92e9a8e)

## Example of $B^+$-tree
![image](https://github.com/user-attachments/assets/5d496260-bff2-41d7-9a71-a7c7c364b84b) <br>
instructor 파일에 대한 $B^+$-트리 (n = 6)
- Leaf nodes의 값이 $3$개 이상 $5$개 이하이어야 한다 $\left( \lceil \frac{n - 1}{2} \rceil, n - 1\text{에서 }n = 6 \right)$.
- root를 제외한 Non-leaf nodes는 자식이 $3$개 이상 $6$개 이하이어야 한다 $\left( \lceil \frac{n}{2} \rceil, n\text{에서 }n = 6 \right)$
- Root 최소한 $2$개의 children을 가져야 한다.

## Observations about $B^+$-trees
- inter-node connections은 pointers로 이루어지므로, 물리적으로 가까울 필요는 없다.
- $B^+$-tree의 non-leaf levels은 hierarchy of sparse indices(희소 인덱스의 계층 구조)를 이룬다.
- $B^+$-tree는 비교적 small number of levels(적은 수의 레벨)을 가진다.
  - Level below root(루트 바로 아래 레벨)은 최소 $2 \times \lceil \frac{n}{2} \rceil$ 개의 값을 가진다.
  - 그 Next level은 최소 $2 \times \lceil \frac{n}{2} \rceil \times \lceil \frac{n}{2} \rceil$ 개의 값을 가진다.
  - file에 search-key values이 $K$개 있다면, tree height는 최대 $\lceil \log_{\lceil n/2 \rceil}(K) \rceil$ 이다.
  - 따라서 searches는 효율적으로 수행될 수 있다.
- main file에 대한 Insertions과 deletions는 index를 로그 시간 내에 재구성할 수 있으므로 효율적으로 처리할 수 있다.

## Queries on $B^+$-Trees
- search-key value V를 가진 record를 찾는다.
  1. $C = \text{root}$
  2. $C$가 leaf node가 아닐 동안 {
     - $V \leq K_i$를 만족하는 최소의 $i$를 찾는다.
     - 그런 $i$가 없다면, $C$를 $C$의 마지막 non-null pointer로 설정한다.
     - Else { if (V = K_i) Set $C = P_{i+1}$ else C = p_i } <br>
   }
  3. $K_i = V$를 만족하는 최소의 $i$를 찾는다.
  4. 그런 $i$가 있다면, pointer $P_i$를 따라 원하는 record로 이동한다.
  5. 없다면, search-key value $V$를 가진 record는 존재하지 않는다. <br>

![image](https://github.com/user-attachments/assets/988bdccb-615f-4fa6-9fe1-dce9952b4efc) <br>
- file에 search-key values이 $K$개 있을 때, tree의 height는 최대 $\lceil \log_{\lceil n/2 \rceil}(K) \rceil$ 이다.
- node는 일반적으로 disk block과 크기가 같으며, 보통 4KB이다.
  - 그리고 $n$은 보통 약 100이다 (인덱스 항목당 40바이트 기준).
- 100개의 분기 수($n=100$)와 100만 개(1 million)의 검색 키 값(search key values)이 있을 때
  - 조회(lookup) 시 최대 $\log_{50}(1,000,000) = 4$ 노드가 접근된다. -> 최악의 경우 B/2 = 50이여서 max 4번이다.  
- 1백만(1 million) 개 검색 키 값을 가진 균형 이진 트리(balanced binary tree)와 비교하면 -> <br>
  조회(lookup) 시 약 20개의 nodes가 접근된다.
  - 이 difference는 중요하다. 왜냐하면 각 node 접근마다 disk I/O가 필요할 수 있고, 이로 인해 약 20 milliseconds의 비용이 들기 때문이다. <br>

![image](https://github.com/user-attachments/assets/7c618d02-cba3-49ba-9d8c-901e7713c12d) <br>
![image](https://github.com/user-attachments/assets/8b82d52c-2ee2-4a79-a6f7-67c2aece68d0) <br>
![image](https://github.com/user-attachments/assets/a2fb0c5b-307e-445e-bdf8-6b07c2aa1721) <br>
![image](https://github.com/user-attachments/assets/c9f09178-f44d-4d1f-a601-bc14c52b849b)

## Updates on $B^+$-Trees: Insertion
1. search-key value이 나타날 leaf node를 찾는다.
2. search-key value이 leaf node에 이미 존재하면
   1. record를 file에 추가한다.
   2. 필요하다면 bucket에 대한 pointer를 추가한다.
      - ex) 이미 '김철수'라는 이름을 가진 레코드가 있으면, 그 leaf node에 새로 들어온 '김철수' 값(즉, 또 다른 '김철수' 레코드)을 추가한다. <br>
  그리고 만약 같은 이름을 가진 레코드가 여러 개라서 bucket(여러 레코드를 모아두는 공간)이 필요하다면, 그 bucket에 새 레코드의 위치를 가리키는 pointer도 추가한다.
3. search-key value이 존재하지 않으면
   1. record를 main file에 추가한다 (필요하다면 bucket도 생성).
   2. leaf node에 공간(room)이 있다면, (key-value, pointer) 쌍을 leaf node에 삽입한다.
   3. 그렇지 않으면, 새로운 (key-value, pointer) 항목과 함께 node를 split한다
- Splitting a leaf node:
  - 삽입할 항목을 포함하여 총 $n$개의 (search-key value, pointer) 쌍을 정렬된 순서로 나열한다. 처음 $⌈n/2⌉$개는 기존 node에, 나머지는 새 node에 배치한다.
  - new node를 $p$, $p$에서 가장 작은 key value을 $k$라고 하면, 분할된 노드의 parent node에 $(k, p)$를 삽입한다.
  - parent node가 가득 차 있다면, 그것도 split하고 분할을 위쪽으로 전파한다.
- 노드 분할은 가득 차지 않은 노드를 만날 때까지 위로 계속 진행된다.
  - worst case, root node까지 분할되며 height of the가 1만큼 증가할 수 있다. <br>

![image](https://github.com/user-attachments/assets/d0a8ad28-296f-4fc7-b407-4287f88b4412)

## $B^+$-Tree Insertion
![image](https://github.com/user-attachments/assets/058e45e9-a9f3-4221-92b2-a1c5dbe22532) <br>
![image](https://github.com/user-attachments/assets/94c94ce2-5e84-41a2-a59d-03fa71b7bd9c) <br>
여기서 봐야할 1가지 특이점이 있다. <br>
- Leaf Node Split vs Internal Node Split의 차이
  - Lamport의 경우 (Leaf Node Split): <br>
  Lamport는 leaf node에 삽입 -> split -> 위로 복사 -> 따라서 leaf + internal 둘다 있다. <br> 
  다만 해당 node가 계속 올라가면 leaf + 최종 도착한곳 2곳에만 있다.
  - Gold의 경우 (Internal Node Split): <br>
  Gold는 Internal node split에서는 중간 key(Gold)를 부모로 이동(push up/move up) 한ㄷ. <br>
  따라서 Gold는 원래 internal node에서 제거되고 상위 노드로만 올라갑니다

## Insertion in B+-Trees (Cont.)
- Splitting a non node N-leaf node: 이미 가득 찬 내부 노드에 (k, p)를 inserting할 때
  - N을 n+1개의 포인터와 n개의 키를 저장할 수 있는 메모리 영역 M으로 복사한다
  - (k, p)를 M에 삽입한다
  - M에서 $P_1$, $K_1$, …, $K_{⌈n/2⌉-1}$, $P_{⌈n/2⌉}$를 다시 노드 N에 복사한다
  - M에서 $P_{⌈n/2⌉+1}$, $K_{⌈n/2⌉+1}$, …, $K_n$, $P_{n+1}$를 새로 할당된 노드 N’에 복사한다
  - ($K_{⌈n/2⌉}$, N’)를 노드 N의 부모에 삽입한다 <br>
위에서 설명한 Internal관련이다. <br>
![image](https://github.com/user-attachments/assets/a65b943d-3053-4b0d-b9c0-effcb8e5ba5a) <br>
![image](https://github.com/user-attachments/assets/649a4843-b016-448a-a18d-889de72090e7) <br>
![image](https://github.com/user-attachments/assets/4c55125d-52be-4b44-b96e-a2bcf9e9b786) <br>

## Examples of $B^+$-Tree Deletion -> deletion은 자세히X 구현X 어느정도 이해만 해두자
![image](https://github.com/user-attachments/assets/7efcc047-1fa1-4173-97f2-b3a288d7f435) <br>
![image](https://github.com/user-attachments/assets/d664dbe1-c42a-4fc9-b334-a487b29e0168) <br>
- Singh와 Wu를 포함하는 leaf가 부족해져서 left sibling node에서 Kim 값을 빌렸다
- 그 결과 부모 노드의  Search-key value이 변경된다 <br>

![image](https://github.com/user-attachments/assets/f3a9112c-f73f-4141-bbba-c55fd18c5ae5) <br>
Gold와 Katz를 가진 노드가 부족해져서 sibling 노드와 merged되었다 <br>
Parent 노드도 부족해져서 Parent의 sibling 노드와 병합되었다 <br>
  두 노드를 구분하는 Value(부모 노드에 있는 값)이 병합될 때 아래로 내려온다 <br>
Root 노드는 자식이 하나만 남아 삭제된다

## Updates on $B^+$-Trees: Deletion
- 삭제할 레코드를 찾아 main file과 bucket(있다면)에서 제거한다
- 버킷이 없거나 버킷이 비어 있으면, leaf 노드에서 (search-key value, pointer)를 제거한다
- 제거로 인해 노드의 엔트리가 너무 적고, 해당 노드와 형제 노드의 엔트리가 하나의 노드에 들어갈 수 있으면, 형제 노드를 병합한다:
  - 두 노드의 모든 search-key values을 하나의 노드(왼쪽 노드)에 삽입하고, 다른 노드는 삭제한다
  - 삭제된 노드를 가리키는 pointer $𝑃_i$와 쌍을 이루는 ($K_{i−1}$, $p_i$)를 부모 노드에서 삭제하며, 위 절차를 재귀적(recursively)으로 수행한다
- 만약 삭제로 인해 노드의 엔트리가 너무 적지만, 해당 노드와 sibling 노드의 엔트리가 하나의 노드에 들어가지 않는 경우에는 pointers를 재분배(redistribute)한다:
  - 노드와 sibling 노드 사이에 pointers를 재분배하여 두 노드 모두 최소 엔트리 수 이상이 되도록 한다.
  - 노드의 부모에 있는 대응(corresponding)하는 search-key value을 업데이트한다.
- 노드 삭제는 위로 연쇄적(cascade)으로 진행될 수 있으며, 포인터가 ⌈n/2⌉개 이상인 노드가 발견될 때까지 계속된다.
- 삭제 후 루트 노드에 포인터가 하나만 남으면, 루트 노드를 삭제하고 그 유일한 자식 노드가 새로운 루트가 된다. -> root node 삭제 -> level이 1개 down <br>

![image](https://github.com/user-attachments/assets/ed58d4b9-7871-44c8-9169-9dba5e1acae8)

## $B^+$-Tree File Organization
- Index file의 열화(degradation) 문제는 $B^+$-Tree indices를 사용함으로써 해결된다.
- Data file의 열화(degradation) 문제는 B 조직(B Organization)을 사용함으로써 해결된다.
- $B^+$-tree file organization에서는 leaf 노드가 포인터 대신 실제 레코드를 저장한다.
- leaf 노드는 여전히 절반 이상 차 있어야 한다.
  - records는 pointers보다 크기 때문에, leaf 노드에 저장할 수 있는 최대 레코드 수는 nonleaf node에 저장할 수 있는 포인터 수보다 적다.
- Insertion과 deletion는 $B^+$-tree index에서의 삽입 및 삭제 방식과 동일하게 처리된다.<br>

![image](https://github.com/user-attachments/assets/2a5cf496-d0b0-4baa-b625-8ed2c1bab730) <br>
- records는 pointers보다 더 많은 공간을 차지하므로, 좋은 space utilization이 중요하다.
- space utilization를 높이기 위해, 분할(split) 및 병합(merge) 시 더 많은 sibling 노드를 재분배에 참여시킨다.
  - 가능한 분할/병합을 피하기 위해 형제 노드 2개를 재분배에 포함시키면, 각 노드는 최소 ⌊2n/3⌋개의 엔트리를 갖게 된다. <br>
![image](https://github.com/user-attachments/assets/9eafbf99-8230-4198-9df8-5647fcfe0ff0)

## Other Issues in Indexing
- Record 재배치(relocation)와 secondary indices
  - 레코드가 이동하면, 레코드 포인터를 저장하는 모든 secondary indices를 업데이트해야 한다.
  - $B^+$-tree file organizations에서의 노드 분할은 매우 비용이 많이 든다. -> 위의 이유때문
  - Solution: secondary index에 레코드 포인터 대신 기본 인덱스 검색 키(primary-index search key)를 사용한다.
  - 레코드를 찾기 위해 기본 인덱스(primary index)를 추가로 탐색(traversal)해야 하므로 쿼리(queries) 비용은 증가하지만, 노드 splits은 저렴해진다.
  - 기본 인덱스 검색 키(primary-index search key)가 유일하지 않다면 레코드 ID(record-id)를 추가한다.<br>

![image](https://github.com/user-attachments/assets/ce17924e-5e08-4849-a731-fb9f967a0861)
