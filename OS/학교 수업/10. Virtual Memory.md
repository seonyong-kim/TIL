# Virtual Memory

## Motivation of Virtual Memory
- 코드와 데이터는 실행을 위해 메모리에 있어야 하지만, 전체 프로그램이 모두 사용되는 경우는 적다.
  - 예: 오류 코드, 특이한 루틴, 대형 데이터 구조 등 어떤 코드는 안 다루기도 한다.
- 부분적으로만 적재된 프로그램(partially-loaded program)을 실행할 수 있는 기능을 고려
  - 프로그램이 더 이상 물리적 메모리(physical memory)의 한계에 제약받지 않는다. -> 제약 X
  - 실행 중인 각 프로그램이 차지하는 메모리 공간이 줄어든다. -> 따라서 동시에 더 많은 프로그램 실행 가능하다. degree of multiprograming 증가.
    - 이에 따라 CPU 활용률(CPU utilization)과 처리량(throughput)이 증가하지만, 응답 시간(response time)이나 반환 시간(turnaround time)은 증가하지 않는다.
  - 프로그램을 메모리에 적재하거나 스와핑할 때 필요한 I/O가 줄어든다. -> 각 사용자 프로그램이 더 빨리 실행됨
- 이러한 장점때문에 virtual memory 시작

## Virtual Memory
- 사용자 논리 메모리(user logical memory)와 물리 메모리(physical memory)를 분리한다.
  - 실행을 위해 프로그램의 일부만 메모리에 있으면 된다.
  - 따라서 Logical address space는 physical address space보다 훨씬 클 수 있음
  - 여러 프로세스가 주소 공간(address spaces)을 공유할 수 있다.
    - 더 효율적인 프로세스 생성이 가능하다.
    - 동시에 더 많은 프로그램 실행 가능
    - Less I/O needed to load or swap processes
- 가상 주소 공간(Virtual address space): 프로세스가 메모리에 저장되는 논리적인 관점
  - 보통 주소 0부터 시작하며, 공간의 끝까지 연속적인 주소 사용
  - 반면, 물리 메모리는 page frames 단위로 구성됨
  - MMU(Memory Management Unit)는 논리 주소를 물리 주소로 매핑해야 함
- Virtual memory는 다음 방식으로 구현 가능
  - Demand paging
  - Demand segmentation

## Virtual Memory(2)
- Virtual memory는 physical memory보다 더 크다 <br>

![image](https://github.com/user-attachments/assets/0805e26e-4b0c-4dea-8526-e2e37495d5d7) <br>

- Virtual address space
  - Contiguous memory space 0 to max (code to stack)
  - Unused address space between stack and heap
  - System libraries shared via mapping into virtual address space
  - Shared memory by mapping pages read-write into virtual address space
  - Pages can be shared during fork(), speeding process creation
  - 0부터 최대치까지 연속적인 메모리 공간 (코드부터 스택까지)
  - 스택과 힙 사이에는 사용되지 않는 주소 공간 존재
  - 시스템 라이브러리는 가상 주소 공간에 매핑하여 공유됨
  - 공유 메모리는 페이지를 read-write 권한으로 가상 주소 공간에 매핑함으로써 가능하다.
  - fork() 중에 페이지를 공유함으로써 프로세스 생성 속도를 높일 수 있음 <br>

![image](https://github.com/user-attachments/assets/3c59ae3e-0fde-4d80-997f-f9cb9b568dd0)
- Shared library using virtual memory <br>

![image](https://github.com/user-attachments/assets/aee7af08-6638-44cd-a793-62bc28f7867d)

# Demand Paging
## Basic Concept of Demand Paging
- 페이지를 메모리에 불러오는 것은 필요할 때만 수행
  - 더 적은 I/O 필요, 불필요한 I/O 없다
  - 더 적은 메모리 필요
  - 더 빠른 응답 속도
  - 더 많은 사용자 가능
- 스와핑(swapping)이 있는 페이징 시스템(paging system)과 유사
- 페이지가 필요할 경우 → 해당 페이지에 대한 참조 발생
  - 잘못된 참조(참조를 해도 되는 부분을 참조하는지 확인) → 중단
  - 메모리에 없음 → 메모리로 불러옴
- Lazy swapper: 페이지가 필요할 때만 메모리에 스와핑
  - 페이지를 다루는 swapper는 pager라고 함<br>
 
![image](https://github.com/user-attachments/assets/63bc860c-5262-491b-9ea5-50c15bede2f0) <br>
- demand paging을 구현하려면 새로운 MMU 기능이 필요하다 -> 추가적으로 주소변환 + memory에 있는지 check
- 필요한 페이지가 이미 메모리에 상주해 있다면
  - non demand-paging 경우와 차이 없다
- 필요한 페이지가 메모리에 없을 경우
  - 페이지가 필요한 것을 감지하고 저장장치(storage)에서 메모리로 로드해야 한다. -> storage어디에 있는지 check
    - 프로그램 동작을 변경하지 않고
    - 프로그래머가 코드를 변경할 필요 없이

## Valid-Invalid Bit -> memory에 있는지 check
- 각 페이지 테이블 항목에는 valid-invalid bit가 연결되어 있다.
  - v → 메모리에 있음 (memory resident)
  - i → 메모리에 없음
- 초기에는 모든 항목의 valid-invalid bit를 i로 설정한다.
- 페이지 테이블 스냅샷 예시: <br>

![image](https://github.com/user-attachments/assets/e8e2d393-cf88-492f-ba67-f42fec4717d2)<br>
- MMU가 주소 변환을 수행하는 동안, valid-invalid bit가 i(invalid)이면 → 페이지 폴트(page fault) 발생(page fault라는 trap을 띄운다)

## Page Table Example
![image](https://github.com/user-attachments/assets/fb47ca61-2fc3-4767-a75f-54971ee782bd)

## Page Fault -> page 접근시 해당 page없다(첫번째 접근)
- 페이지에 대한 참조가 있을 때, 해당 페이지에 대한 첫 번째 참조(접근해도 되는 주소인지 확인)는 운영체제로 trap(페이지 폴트)된다.
1. 운영체제는 다른 테이블을 확인하여 결정한다:
  - 잘못된 참조 → 중단(abort) -> 끝
  - 단지 메모리에 없다. -> 2번으로
2. 빈 프레임(free frame) 찾기 -> 빈 frame 찾기(빈칸이 있다 가정)
3. 예약된 디스크 작업(scheduled disk operation)을 통해 페이지를 프레임으로 교체(Swap)한다.
4. 페이지가 현재 메모리에 있음을 나타내도록 테이블을 재설정하고 valid-invalid bit = v로 설정
5. 페이지 폴트( page fault)를 발생시킨 명령어 재시작 -> page fault 야기한 instruction 저대로 수행X -> 다시 처음부터 시작한다. <br>

![image](https://github.com/user-attachments/assets/945a525f-da2c-4edf-a32a-8293cff1b9cc)

## Characteristics of Demand Paging
- Pure demand paging: 프로세스를 메모리에 아무 페이지도 없는 상태에서 시작한다.
  - 운영체제가 프로세스의 첫 번째 명령어로 명령어 포인터를 설정 후 해당 명령어가 메모리에 없으면 → page fault 발생
  - 그리고 다른 모든 프로세스 페이지들도 첫 접근 시마다 발생
- 실제로, 특정 명령어는 여러 페이지에 접근할 수 있음 → 여러 개의 페이지 폴트 발생 가능
  - 예: 두 개의 메모리 숫자를 더하고 결과를 다시 메모리에 저장하는 명령어의 가져오기(fetch)와 디코딩(decode) 과정
  - 참조 지역성(locality of reference) 때문에 이런 고통은 감소 -> 매번 page fault 야기는 드물다.
- demand paging을 위한 하드웨어 지원 필요
  - valid / invalid bit를 가진 Page table (MMU)
  - 보조 기억장치(Secondary memory) (스왑 장치) -> backing store
  - 명령어 재시작

## Instruction Restart
- 프로세스를 계속 실행하는 것은 매우 까다롭다. 왜냐하면 page fault가 명령어 수행 중간에 발생했을 수 있기 때문이다.
  - 사용자 프로세스는 page fault가 발생했다는 사실조차 몰라야 한다.
  - 명령어를 그냥 건너뛸 수 있을까?
    - NO: 프로세스가 그 변화를 인지하게 된다
  - 명령어를 처음부터 다시 시작해야 한다.
    - 자동 증가/감소(auto increment/decrement) 같은 명령어는 어떻게 해야 할까?
  - 명령어를 재시작하기 위한 하드웨어 지원이 필요하다.
 
## TLB Fault vs. Page Fault
- 메모리 관련 오류에는 두 가지가 있다:
  - TLB fault (TLB 오류)
    - 필요한 가상 → 물리 주소 변환 정보가 TLB에 없다
  - Page fault (페이지 폴트)
    - 가상 페이지의 내용이 아직 초기화되지 않았거나 메모리에 없음
- 중요한 사실들:
  - 모든 Page fault는 TLB fault보다 뒤에 발생한다
    - 가상 페이지의 내용이 메모리에 없다면, 그에 대한 변환 정보(TLB 엔트리)는 존재할 수 없다
  - 모든 TLB fault가 Page fault를 유발하지는 않는다
    - 페이지가 메모리에 있고, 변환 정보가 페이지 테이블에 있다면 → TLB에 다시 채워 넣음으로써 page fault 없이 처리 가능 <br>

![image](https://github.com/user-attachments/assets/9430a5de-a2a6-4dea-a40a-3154036be8d6)

## Stages in Demand Paging -> page fault 일어난 직후
1. OS로 Trap 발생
2. user registers와 process state 저장 -> page fault handler 돈다.
3. interrupt가 page fault였는지 확인
4. 페이지 참조가 유효한지 확인하고 디스크에서 페이지 위치 확인
5. 디스크에서 free frame으로 읽기 요청 -> disk로 부터 하나 가져온다.
   - 1. 이 장치의 읽기 요청이 처리될 때까지 대기열에서 기다린다.
   - 2. 장치 탐색 시간 및/또는 지연 시간을 기다린다.
   - 3. 페이지를 빈 프레임(free frame)으로 전송하기 시작한다.
6. 대기 중에는 CPU를 다른 사용자(프로세스)에게 할당
7. 디스크 I/O 서브시스템(disk I/O subsystem)으로부터 인터럽트(interrupt) 수신 (I/O 완료됨)
8. other user(프로세스)의 레지스터와 상태 저장 -> 백업
9. interrupt가 disk로부터 왔는지 확인
10. 페이지가 이제 메모리에 있음을 나타내도록 페이지 테이블 및 기타 테이블 수정
10-2. ready queue에 pqge fault 야기한 process 넣어준다.
11. 이 프로세스에 다시 CPU가 할당될 때까지 대기
12. user registers, process state, new page table 복원 후, interrupted돤 명령어 재개

## Performance of Demand Paging (1)
- 세 가지 주요 동작
  - 인터럽트 처리(Service the interrupt): 신중한 코딩 덕분에 수백 개의 명령어만 필요
  - Read the page and write the victim(교체) page (swap): 많은 시간이 소요됨 -> 제일 오래 걸림
  - Restart the process: 다시 소량의 시간만 필요 
- Page fault rate (p): 0 ≤ 𝑝 ≤ 1 -> 메모리접근당 page fault 비율
  - if p = 0: page faults 없다.
  - if p = 1: 매번 참조가 fault
- Effective Access Time (EAT)
  - EAT = (1-p) * memory access time(page hit인 경우 access time) + p * (page fault overhead + swap page out + swap page in) <br>
  swap page out + swap page in이게 커서 묻힌다.
- Example
  - Memory access time = 100 ns
  - Average page-fault service time = 8 ms (page fault overhead + swap in/out time)
  - EAT = (1-p)*100 + p * 8,000,000 = 100 + p * 7,999,900

- In this case, if one access out of 1,000 causes a page fault (p = 0.001), then
  - EAT = 8.1us -> 1000번중 1번이여도 평균적으로 80배 증가한다

- 성능 저하를 10% 미만으로 원한다면 (EAT < 110 ns)
  - 110 > 100 + p * 7,999,900 <br>
  -> 10 > p * 7,999,900 <br>
  -> p < 0.00000125 <br>
  - one page fault in every 800,000 memory access -> page fault 잘 일어나면 안된다.

# Page Selection
## Key Issues in Demand Paging
- Page selection -> 어떤 page 언제?
- Page replacement -> 어떤 page out?
- Page frame allocation -> 균등 or 독점?

## Page Selection
- Page selection policies
  - Demand paging
    - process 시작 시 어떤 페이지도 로드하지 않음
    - 해당 페이지에 대한 page fault가 발생했을 때 로드
      - 반드시 memory에 있어야 할 때까지 기다린다.
    - Almost all paging systems이 이렇게 동작함
  - Prepaging
    - 참조되기 전에 page를 memory에 가져옴
    - 어떤 page가 참조되면, 혹시 몰라 그 다음 페이지도 가져옴
    - 예언이 없는 이상 효과적으로 하기 어려움
    - 가끔은 효과 있음: 순차적 읽기 예측(sequential read-ahead)
  - Request paging
    - user가 어떤 pages가 필요한지 말하게 한다.
    - 이 방식의 문제는
    - Users가 항상 최선의 선택을 하지 않으며, 공정하지 않다.
  - Copy-on-Write(COW, 쓰기 시 복사)는 parent와 child processes가 처음에는 동일한 memory pages를 공유하도록 허용한다.
    - 두 process 중 하나라도 shared page를 수정하면, 그때서야 해당 page가 복사된다.
  - COW는 modified pages만 복사하므로, 프로세스를 더 효율적으로 생성할 수 있게 해준다.
  - 일반적으로, free pages는 '요청 시 0으로 채워지는(zero-fill-on-demand, OS가 관리)' 페이지 풀에서 할당된다.
    - 빠른 요청 페이징을 위해 이 풀에는 항상 여유 프레임이 있어야 함
      - 페이지 폴트 시 프레임을 해제하고 다른 처리를 동시에 하게 하고 싶진 않다.
    - 페이지를 할당하기 전에 0으로 초기화하는 이유는? <br>
    -> 이전 process가 사용하던 원래 data가 남이있는데 전부 덮어쓰는게 아니라면 이전 process가 사용하던 일부 data가 남는다 <br>
    -> 보안문제 발생
  - vfork()는 fork() system call의 변형으로, 부모 프로세스를 일시 중단하고 자식이 부모의 주소 공간(COW 방식)을 사용한다.
    - 자식 프로세스가 exec()를 호출하도록 설계되었다.
    - 매우 효율적이다.<br>

![image](https://github.com/user-attachments/assets/2363a314-07e3-46de-b80a-8f24a5e90013)<br>
![image](https://github.com/user-attachments/assets/fb80ea6a-2afa-40a3-b338-b2d57e7e73e0)

## Page Replacement
- Page replacement – memory에 있지만 실제로 사용되지 않는 페이지를 찾아서 page it out한다.
  1. disk에서 원하는 페이지의 위치를 찾는다.
  2. free frame을 찾는다.
     - free frame이 있다면 그것을 사용
     - free frame이 없다면, page replacement algorithm을 사용해 victim frame을 선택
       - victim frame이 dirty(수정된 상태)라면 disk에 저장한다. <br>
       수정된적이 없으면 그냥 버려도 된다.(disk에 원본 data가 있어서)
  3. 원하는 페이지를 (새롭게) free frame에 가져온다. page and frame tables을 갱신한다.
  4. 트랩(trap)을 발생시킨 명령어를 다시 시작하면서 프로세스를 계속 진행
  - 주의: page fault시 최대 2번의 페이지 전송(page-in, page-out)이 발생할 수 있음 → 유효 접근 시간(EAT)이 증가함<br>

![image](https://github.com/user-attachments/assets/ff61466b-0097-406a-8d8a-5a20094d6d13)

## Page Replacement Algorithms (1)
 • Page replacement algorithms
 • Want lowest page-fault rate on both first access and re-access
 • Evaluate algorithm by running it on a particular string of memory references 
(reference string) and computing the number of page faults on that string
 • String is just page numbers, not full addresses
 • Repeated access to the same page does not cause a page fault
 • Results depend on number of frames available
 • In all our examples, the reference string of referenced page number is
 • 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1

- Page replacement algorithms
  - first access and re-access 모두에서 page-fault rate이 가장 낮기를 원한다.
- algorithm 평가할 때는 특정한 메모리 참조 문자열(reference string)을 사용해 number of page faults on that string를 계산한다.
  - 이 문자열은 full addresses가 아닌 page numbers만 포함한다.
  - 동일한 페이지를 반복해서 접근해도 page fault는 발생하지 않는다.
  - 결과는 사용 가능한 frames 수에 따라 달라진다.
- 우리가 예제로 사용할 참조 문자열(reference string)은 다음과 같다:
  - 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
- Random: 임의의 페이지를 무작위로 선택해 교체한다.
  - 놀랍게도 꽤 잘 작동한다!
- FIFO(First-In, First-Out): 메모리에 가장 오래 있었던 페이지를 제거
  - 공정성을 위한 아이디어
  - 모든 페이지에게 동일한 체류 시간을 준다.
- OPT(Optimal): 앞으로 가장 오랫동안 사용되지 않을 페이지를 제거
  - 언제나 그렇듯, 미래를 예측할 수 있다면 가장 좋은 알고리즘이 됨
  - 실제로 구현하기는 어렵지만, 비교 기준으로는 매우 좋음
- LRU(Least Recently Used): 가장 오랫동안 사용되지 않은 페이지를 제거
  - 과거의 사용 기록을 바탕으로 미래를 예측
  - 지역성(locality)이 있는 경우, LRU는 Optimal에 가깝게 동작함

## FIFO Algorithm (1)
- Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
- 3 frames (3 pages can be in memory at a time per process) <br>
 
![image](https://github.com/user-attachments/assets/e3464be4-df17-4185-8bda-5dc83402a69a) <br>
- Belady’s Anomaly
  - Adding more frames can cause more page faults! (compare FIFO with 3 and 4 frames)
  - frame을 더 추가하면 오히려 page fault가 증가할 수 있다! (예: FIFO에서 frame 수가 3개일 때와 4개일 때를 비교)
  - Consider 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 <br>

![image](https://github.com/user-attachments/assets/59a66eb9-a92e-437d-8880-ae8df82f64f1)

## Optimal (OPT) Algorithm
- 가장 오랫동안 사용되지 않을 페이지를 교체한다.
- 이 방식은 자신의 알고리즘이 얼마나 잘 작동하는지 평가할 때 기준으로 사용된다.
- Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 <br>

![image](https://github.com/user-attachments/assets/7970a26d-dd1c-484b-93c8-89bb288acc89)

## LRU (Least Recently Used) Algorithm (OPT와 비슷하게 하기 위해 만듬)
- 미래가 아닌 과거의 정보를 활용한다.
- 가장 오랫동안 사용되지 않은 페이지를 교체한다.
- Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 <br>

![image](https://github.com/user-attachments/assets/78a26860-bc35-48af-aa75-779e054beb48)
- Stack algorithm
  - n개의 frames에 있는 페이지 집합은 항상 n+1개의 frames에 있는 페이지 집합의 부분집합이다.
- LRU와 OPT는 Belady의 역설이 없는 stack algorithms의 예이다.
- 구현방법?
- 두 가지 구현 방법
  - Counter implementation
    - 모든 페이지 항목에 카운터가 있다. 페이지가 참조될 때마다 clock(시간 정보 기록)을 카운터에 복사한다.
    - 페이지를 교체할 때는 가장 작은 값을 가진 카운터를 찾는다.
      - 테이블을 검색해야 한다. <br>

![image](https://github.com/user-attachments/assets/c25d8c61-2826-476a-94e0-9742aa3deeb9) <br>
  - Stack implementation
    - page numbers를 이중 연결 형태의 스택으로 유지한다.
    - 페이지가 참조되면
      - 스택 맨 위로 이동
    - 최대 6개의 pointer만 변경 필요
    - 하지만 각 업데이트 비용이 더 큼
    - 교체할 페이지를 찾기 위한 검색 불필요 <br>

![image](https://github.com/user-attachments/assets/1b544b16-025b-46f6-af38-4915ad5c2c52) <br>
- Stack implementation example <br>

![image](https://github.com/user-attachments/assets/4b2f2c7a-faeb-4c4f-a31b-35047c093ad8)

## LRU Approximations
 • Basic: make use of hardware support: reference bit (use bit)
 • Initially, reference bit = 0
 • When page is accessed, reference bit = 1
 • Replace any with reference bit = 0 (if one exist)
 • We do not know the order, however
 • Additional-Reference Bits Algorithm
 • Second-Chance Algorithm (Clock Algorithm)
 • Enhanced Clock Algorithm
 • Counting-Based Algorithm
- Basic: HW support(간단한 clock algorithm) —> reference bit(사용 비트) 1bit
  - 처음에는 reference bit = 0
  - 페이지가 접근되면 reference bit = 1
  - 주기적으로 reference bit = 0으로 초기화 해준다.
  - reference bit가 0인 페이지가 있으면 그 페이지를 교체 -> 0이 의미하는 바는 <br>
  주기적인 초기화 이후 해당 페이지에 접근이 없었다는 말이다.
    - 다만, 교체 순서는 알 수 없다.
- Additional-Reference Bits Algorithm
- Second-Chance Algorithm (Clock Algorithm)
- Enhanced Clock Algorithm
- Counting-Based Algorithm
