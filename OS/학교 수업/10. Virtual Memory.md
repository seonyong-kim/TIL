# Virtual Memory

## Motivation of Virtual Memory
- 코드와 데이터는 실행을 위해 메모리에 있어야 하지만, 전체 프로그램이 모두 사용되는 경우는 적다.
  - 예: 오류 코드, 특이한 루틴, 대형 데이터 구조 등 어떤 코드는 안 다루기도 한다.
- 부분적으로만 적재된 프로그램(partially-loaded program)을 실행할 수 있는 기능을 고려
  - 프로그램이 더 이상 물리적 메모리(physical memory)의 한계에 제약받지 않는다. -> 제약 X
  - 실행 중인 각 프로그램이 차지하는 메모리 공간이 줄어든다. -> 따라서 동시에 더 많은 프로그램 실행 가능하다. degree of multiprograming 증가.
    - 이에 따라 CPU 활용률(CPU utilization)과 처리량(throughput)이 증가하지만, 응답 시간(response time)이나 반환 시간(turnaround time)은 증가하지 않는다.
  - 프로그램을 메모리에 적재하거나 스와핑할 때 필요한 I/O가 줄어든다. -> 각 사용자 프로그램이 더 빨리 실행됨
- 이러한 장점때문에 virtual memory 시작

## Virtual Memory
- 사용자 논리 메모리(user logical memory)와 물리 메모리(physical memory)를 분리한다.
  - 실행을 위해 프로그램의 일부만 메모리에 있으면 된다.
  - 따라서 Logical address space는 physical address space보다 훨씬 클 수 있음
  - 여러 프로세스가 주소 공간(address spaces)을 공유할 수 있다.
    - 더 효율적인 프로세스 생성이 가능하다.
    - 동시에 더 많은 프로그램 실행 가능
    - Less I/O needed to load or swap processes
- 가상 주소 공간(Virtual address space): 프로세스가 메모리에 저장되는 논리적인 관점
  - 보통 주소 0부터 시작하며, 공간의 끝까지 연속적인 주소 사용
  - 반면, 물리 메모리는 page frames 단위로 구성됨
  - MMU(Memory Management Unit)는 논리 주소를 물리 주소로 매핑해야 함
- Virtual memory는 다음 방식으로 구현 가능
  - Demand paging
  - Demand segmentation

## Virtual Memory(2)
- Virtual memory는 physical memory보다 더 크다 <br>

![image](https://github.com/user-attachments/assets/0805e26e-4b0c-4dea-8526-e2e37495d5d7) <br>

- Virtual address space
  - Contiguous memory space 0 to max (code to stack)
  - Unused address space between stack and heap
  - System libraries shared via mapping into virtual address space
  - Shared memory by mapping pages read-write into virtual address space
  - Pages can be shared during fork(), speeding process creation
  - 0부터 최대치까지 연속적인 메모리 공간 (코드부터 스택까지)
  - 스택과 힙 사이에는 사용되지 않는 주소 공간 존재
  - 시스템 라이브러리는 가상 주소 공간에 매핑하여 공유됨
  - 공유 메모리는 페이지를 read-write 권한으로 가상 주소 공간에 매핑함으로써 가능하다.
  - fork() 중에 페이지를 공유함으로써 프로세스 생성 속도를 높일 수 있음 <br>

![image](https://github.com/user-attachments/assets/3c59ae3e-0fde-4d80-997f-f9cb9b568dd0)
- Shared library using virtual memory <br>

![image](https://github.com/user-attachments/assets/aee7af08-6638-44cd-a793-62bc28f7867d)

# Demand Paging
## Basic Concept of Demand Paging
- 페이지를 메모리에 불러오는 것은 필요할 때만 수행
  - 더 적은 I/O 필요, 불필요한 I/O 없다
  - 더 적은 메모리 필요
  - 더 빠른 응답 속도
  - 더 많은 사용자 가능
- 스와핑(swapping)이 있는 페이징 시스템(paging system)과 유사
- 페이지가 필요할 경우 → 해당 페이지에 대한 참조 발생
  - 잘못된 참조(참조를 해도 되는 부분을 참조하는지 확인) → 중단
  - 메모리에 없음 → 메모리로 불러옴
- Lazy swapper: 페이지가 필요할 때만 메모리에 스와핑
  - 페이지를 다루는 swapper는 pager라고 함<br>
 
![image](https://github.com/user-attachments/assets/63bc860c-5262-491b-9ea5-50c15bede2f0) <br>
- demand paging을 구현하려면 새로운 MMU 기능이 필요하다 -> 추가적으로 주소변환 + memory에 있는지 check
- 필요한 페이지가 이미 메모리에 상주해 있다면
  - non demand-paging 경우와 차이 없다
- 필요한 페이지가 메모리에 없을 경우
  - 페이지가 필요한 것을 감지하고 저장장치(storage)에서 메모리로 로드해야 한다. -> storage어디에 있는지 check
    - 프로그램 동작을 변경하지 않고
    - 프로그래머가 코드를 변경할 필요 없이

## Valid-Invalid Bit -> memory에 있는지 check
- 각 페이지 테이블 항목에는 valid-invalid bit가 연결되어 있다.
  - v → 메모리에 있음 (memory resident)
  - i → 메모리에 없음
- 초기에는 모든 항목의 valid-invalid bit를 i로 설정한다.
- 페이지 테이블 스냅샷 예시: <br>

![image](https://github.com/user-attachments/assets/e8e2d393-cf88-492f-ba67-f42fec4717d2)<br>
- MMU가 주소 변환을 수행하는 동안, valid-invalid bit가 i(invalid)이면 → 페이지 폴트(page fault) 발생(page fault라는 trap을 띄운다)

## Page Table Example
![image](https://github.com/user-attachments/assets/fb47ca61-2fc3-4767-a75f-54971ee782bd)

## Page Fault -> page 접근시 해당 page없다(첫번째 접근)
- 페이지에 대한 참조가 있을 때, 해당 페이지에 대한 첫 번째 참조(접근해도 되는 주소인지 확인)는 운영체제로 trap(페이지 폴트)된다.
1. 운영체제는 다른 테이블을 확인하여 결정한다:
  - 잘못된 참조 → 중단(abort) -> 끝
  - 단지 메모리에 없다. -> 2번으로
2. 빈 프레임(free frame) 찾기 -> 빈 frame 찾기(빈칸이 있다 가정)
3. 예약된 디스크 작업(scheduled disk operation)을 통해 페이지를 프레임으로 교체(Swap)한다.
4. 페이지가 현재 메모리에 있음을 나타내도록 테이블을 재설정하고 valid-invalid bit = v로 설정
5. 페이지 폴트( page fault)를 발생시킨 명령어 재시작 -> page fault 야기한 instruction 저대로 수행X -> 다시 처음부터 시작한다. <br>

![image](https://github.com/user-attachments/assets/945a525f-da2c-4edf-a32a-8293cff1b9cc)

## Characteristics of Demand Paging
- Pure demand paging: 프로세스를 메모리에 아무 페이지도 없는 상태에서 시작한다.
  - 운영체제가 프로세스의 첫 번째 명령어로 명령어 포인터를 설정 후 해당 명령어가 메모리에 없으면 → page fault 발생
  - 그리고 다른 모든 프로세스 페이지들도 첫 접근 시마다 발생
- 실제로, 특정 명령어는 여러 페이지에 접근할 수 있음 → 여러 개의 페이지 폴트 발생 가능
  - 예: 두 개의 메모리 숫자를 더하고 결과를 다시 메모리에 저장하는 명령어의 가져오기(fetch)와 디코딩(decode) 과정
  - 참조 지역성(locality of reference) 때문에 이런 고통은 감소 -> 매번 page fault 야기는 드물다.
- demand paging을 위한 하드웨어 지원 필요
  - valid / invalid bit를 가진 Page table (MMU)
  - 보조 기억장치(Secondary memory) (스왑 장치) -> backing store
  - 명령어 재시작

## Instruction Restart
- 프로세스를 계속 실행하는 것은 매우 까다롭다. 왜냐하면 page fault가 명령어 수행 중간에 발생했을 수 있기 때문이다.
  - 사용자 프로세스는 page fault가 발생했다는 사실조차 몰라야 한다.
  - 명령어를 그냥 건너뛸 수 있을까?
    - NO: 프로세스가 그 변화를 인지하게 된다
  - 명령어를 처음부터 다시 시작해야 한다.
    - 자동 증가/감소(auto increment/decrement) 같은 명령어는 어떻게 해야 할까?
  - 명령어를 재시작하기 위한 하드웨어 지원이 필요하다.
 
## TLB Fault vs. Page Fault
- 메모리 관련 오류에는 두 가지가 있다:
  - TLB fault (TLB 오류)
    - 필요한 가상 → 물리 주소 변환 정보가 TLB에 없다
  - Page fault (페이지 폴트)
    - 가상 페이지의 내용이 아직 초기화되지 않았거나 메모리에 없음
- 중요한 사실들:
  - 모든 Page fault는 TLB fault보다 뒤에 발생한다
    - 가상 페이지의 내용이 메모리에 없다면, 그에 대한 변환 정보(TLB 엔트리)는 존재할 수 없다
  - 모든 TLB fault가 Page fault를 유발하지는 않는다
    - 페이지가 메모리에 있고, 변환 정보가 페이지 테이블에 있다면 → TLB에 다시 채워 넣음으로써 page fault 없이 처리 가능 <br>

![image](https://github.com/user-attachments/assets/9430a5de-a2a6-4dea-a40a-3154036be8d6)

## Stages in Demand Paging -> page fault 일어난 직후
1. OS로 Trap 발생
2. user registers와 process state 저장 -> page fault handler 돈다.
3. interrupt가 page fault였는지 확인
4. 페이지 참조가 유효한지 확인하고 디스크에서 페이지 위치 확인
5. 디스크에서 free frame으로 읽기 요청 -> disk로 부터 하나 가져온다.
   - 1. 이 장치의 읽기 요청이 처리될 때까지 대기열에서 기다린다.
   - 2. 장치 탐색 시간 및/또는 지연 시간을 기다린다.
   - 3. 페이지를 빈 프레임(free frame)으로 전송하기 시작한다.
6. 대기 중에는 CPU를 다른 사용자(프로세스)에게 할당
7. 디스크 I/O 서브시스템(disk I/O subsystem)으로부터 인터럽트(interrupt) 수신 (I/O 완료됨)
8. other user(프로세스)의 레지스터와 상태 저장 -> 백업
9. interrupt가 disk로부터 왔는지 확인
10. 페이지가 이제 메모리에 있음을 나타내도록 페이지 테이블 및 기타 테이블 수정
10-2. ready queue에 pqge fault 야기한 process 넣어준다.
11. 이 프로세스에 다시 CPU가 할당될 때까지 대기
12. user registers, process state, new page table 복원 후, interrupted돤 명령어 재개

## Performance of Demand Paging (1)
- 세 가지 주요 동작
  - 인터럽트 처리(Service the interrupt): 신중한 코딩 덕분에 수백 개의 명령어만 필요
  - Read the page and write the victim(교체) page (swap): 많은 시간이 소요됨 -> 제일 오래 걸림
  - Restart the process: 다시 소량의 시간만 필요 
- Page fault rate (p): 0 ≤ 𝑝 ≤ 1 -> 메모리접근당 page fault 비율
  - if p = 0: page faults 없다.
  - if p = 1: 매번 참조가 fault
- Effective Access Time (EAT)
  - EAT = (1-p) * memory access time(page hit인 경우 access time) + p * (page fault overhead + swap page out + swap page in) <br>
  swap page out + swap page in이게 커서 묻힌다.
- Example
  - Memory access time = 100 ns
  - Average page-fault service time = 8 ms (page fault overhead + swap in/out time)
  - EAT = (1-p)*100 + p * 8,000,000 = 100 + p * 7,999,900

- In this case, if one access out of 1,000 causes a page fault (p = 0.001), then
  - EAT = 8.1us -> 1000번중 1번이여도 평균적으로 80배 증가한다

- 성능 저하를 10% 미만으로 원한다면 (EAT < 110 ns)
  - 110 > 100 + p * 7,999,900 <br>
  -> 10 > p * 7,999,900 <br>
  -> p < 0.00000125 <br>
  - one page fault in every 800,000 memory access -> page fault 잘 일어나면 안된다.

# Page Selection
## Key Issues in Demand Paging
- Page selection -> 어떤 page 언제?
- Page replacement -> 어떤 page out?
- Page frame allocation -> 균등 or 독점?

## Page Selection
- Page selection policies
  - Demand paging
    - process 시작 시 어떤 페이지도 로드하지 않음
    - 해당 페이지에 대한 page fault가 발생했을 때 로드
      - 반드시 memory에 있어야 할 때까지 기다린다.
    - Almost all paging systems이 이렇게 동작함
  - Prepaging
    - 참조되기 전에 page를 memory에 가져옴
    - 어떤 page가 참조되면, 혹시 몰라 그 다음 페이지도 가져옴
    - 예언이 없는 이상 효과적으로 하기 어려움
    - 가끔은 효과 있음: 순차적 읽기 예측(sequential read-ahead)
  - Request paging
    - user가 어떤 pages가 필요한지 말하게 한다.
    - 이 방식의 문제는
    - Users가 항상 최선의 선택을 하지 않으며, 공정하지 않다.
  - Copy-on-Write(COW, 쓰기 시 복사)는 parent와 child processes가 처음에는 동일한 memory pages를 공유하도록 허용한다.
    - 두 process 중 하나라도 shared page를 수정하면, 그때서야 해당 page가 복사된다.
  - COW는 modified pages만 복사하므로, 프로세스를 더 효율적으로 생성할 수 있게 해준다.
  - 일반적으로, free pages는 '요청 시 0으로 채워지는(zero-fill-on-demand, OS가 관리)' 페이지 풀에서 할당된다.
    - 빠른 요청 페이징을 위해 이 풀에는 항상 여유 프레임이 있어야 함
      - 페이지 폴트 시 프레임을 해제하고 다른 처리를 동시에 하게 하고 싶진 않다.
    - 페이지를 할당하기 전에 0으로 초기화하는 이유는? <br>
    -> 이전 process가 사용하던 원래 data가 남이있는데 전부 덮어쓰는게 아니라면 이전 process가 사용하던 일부 data가 남는다 <br>
    -> 보안문제 발생
  - vfork()는 fork() system call의 변형으로, 부모 프로세스를 일시 중단하고 자식이 부모의 주소 공간(COW 방식)을 사용한다.
    - 자식 프로세스가 exec()를 호출하도록 설계되었다.
    - 매우 효율적이다.<br>

![image](https://github.com/user-attachments/assets/2363a314-07e3-46de-b80a-8f24a5e90013)<br>
![image](https://github.com/user-attachments/assets/fb80ea6a-2afa-40a3-b338-b2d57e7e73e0)

## Page Replacement
- Page replacement – memory에 있지만 실제로 사용되지 않는 페이지를 찾아서 page it out한다.
  1. disk에서 원하는 페이지의 위치를 찾는다.
  2. free frame을 찾는다.
     - free frame이 있다면 그것을 사용
     - free frame이 없다면, page replacement algorithm을 사용해 victim frame을 선택
       - victim frame이 dirty(수정된 상태)라면 disk에 저장한다. <br>
       수정된적이 없으면 그냥 버려도 된다.(disk에 원본 data가 있어서)
  3. 원하는 페이지를 (새롭게) free frame에 가져온다. page and frame tables을 갱신한다.
  4. 트랩(trap)을 발생시킨 명령어를 다시 시작하면서 프로세스를 계속 진행
  - 주의: page fault시 최대 2번의 페이지 전송(page-in, page-out)이 발생할 수 있음 → 유효 접근 시간(EAT)이 증가함<br>

![image](https://github.com/user-attachments/assets/ff61466b-0097-406a-8d8a-5a20094d6d13)

## Page Replacement Algorithms
- Page replacement algorithms
  - first access and re-access 모두에서 page-fault rate이 가장 낮기를 원한다.
- algorithm 평가할 때는 특정한 메모리 참조 문자열(reference string)을 사용해 number of page faults on that string를 계산한다.
  - 이 문자열은 full addresses가 아닌 page numbers만 포함한다.
  - 동일한 페이지를 반복해서 접근해도 page fault는 발생하지 않는다.
  - 결과는 사용 가능한 frames 수에 따라 달라진다.
- 우리가 예제로 사용할 참조 문자열(reference string)은 다음과 같다:
  - 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
- Random: 임의의 페이지를 무작위로 선택해 교체한다.
  - 놀랍게도 꽤 잘 작동한다!
- FIFO(First-In, First-Out): 메모리에 가장 오래 있었던 페이지를 제거
  - 공정성을 위한 아이디어
  - 모든 페이지에게 동일한 체류 시간을 준다.
- OPT(Optimal): 앞으로 가장 오랫동안 사용되지 않을 페이지를 제거
  - 언제나 그렇듯, 미래를 예측할 수 있다면 가장 좋은 알고리즘이 됨
  - 실제로 구현하기는 어렵지만, 비교 기준으로는 매우 좋음
- LRU(Least Recently Used): 가장 오랫동안 사용되지 않은 페이지를 제거
  - 과거의 사용 기록을 바탕으로 미래를 예측
  - 지역성(locality)이 있는 경우, LRU는 Optimal에 가깝게 동작함

## FIFO Algorithm 
- Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
- 3 frames (3 pages can be in memory at a time per process) <br>
 
![image](https://github.com/user-attachments/assets/e3464be4-df17-4185-8bda-5dc83402a69a) <br>
- Belady’s Anomaly
  - Adding more frames can cause more page faults! (compare FIFO with 3 and 4 frames)
  - frame을 더 추가하면 오히려 page fault가 증가할 수 있다! (예: FIFO에서 frame 수가 3개일 때와 4개일 때를 비교)
  - Consider 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 <br>

![image](https://github.com/user-attachments/assets/59a66eb9-a92e-437d-8880-ae8df82f64f1)

## Optimal (OPT) Algorithm
- 가장 오랫동안 사용되지 않을 페이지를 교체한다.
- 이 방식은 자신의 알고리즘이 얼마나 잘 작동하는지 평가할 때 기준으로 사용된다.
- Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 <br>

![image](https://github.com/user-attachments/assets/7970a26d-dd1c-484b-93c8-89bb288acc89)

## LRU (Least Recently Used) Algorithm (OPT와 비슷하게 하기 위해 만듬)
- 미래가 아닌 과거의 정보를 활용한다.
- 가장 오랫동안 사용되지 않은 페이지를 교체한다.
- Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 <br>

![image](https://github.com/user-attachments/assets/78a26860-bc35-48af-aa75-779e054beb48)
- Stack algorithm
  - n개의 frames에 있는 페이지 집합은 항상 n+1개의 frames에 있는 페이지 집합의 부분집합이다.
- LRU와 OPT는 Belady의 역설이 없는 stack algorithms의 예이다.
- 구현방법?
- 두 가지 구현 방법
  - Counter implementation
    - 모든 페이지 항목에 카운터가 있다. 페이지가 참조될 때마다 clock(시간 정보 기록)을 카운터에 복사한다.
    - 페이지를 교체할 때는 가장 작은 값을 가진 카운터를 찾는다.
      - 테이블을 검색해야 한다. <br>

![image](https://github.com/user-attachments/assets/c25d8c61-2826-476a-94e0-9742aa3deeb9) <br>
  - Stack implementation
    - page numbers를 이중 연결 형태의 스택으로 유지한다.
    - 페이지가 참조되면
      - 스택 맨 위로 이동
    - 최대 6개의 pointer만 변경 필요
    - 하지만 각 업데이트 비용이 더 큼
    - 교체할 페이지를 찾기 위한 검색 불필요 <br>

![image](https://github.com/user-attachments/assets/1b544b16-025b-46f6-af38-4915ad5c2c52) <br>
- Stack implementation example <br>

![image](https://github.com/user-attachments/assets/4b2f2c7a-faeb-4c4f-a31b-35047c093ad8)

## LRU Approximations
- Basic: HW support(간단한 clock algorithm) —> reference bit(사용 비트) 1bit
  - 처음에는 reference bit = 0
  - 페이지가 접근되면 reference bit = 1
  - 주기적으로 reference bit = 0으로 초기화 해준다.
  - reference bit가 0인 페이지가 있으면 그 페이지를 교체 -> 0이 의미하는 바는 <br>
  주기적인 초기화 이후 해당 페이지에 접근이 없었다는 말이다.
    - 다만, 교체 순서는 알 수 없다.
- Additional-Reference Bits Algorithm
- Second-Chance Algorithm (Clock Algorithm)
- Enhanced Clock Algorithm
- Counting-Based Algorithm

## LRU Approximations: Additional-Reference Bits
- 각 페이지는 reference bit와 8-bit register를 가진다 -> 추가적인 refernece bit -> 9 bit된다.
  - 이 레지스터를 reference byte라고 한다  
- 일정한 간격으로, (R-비트, R-바이트)을 오른쪽으로 shift한다. -> 즉, 주기적으로 오른쪽으로 1칸 shift  
- the smallest register value을 가진 페이지가 LRU(Least Recently Used) 페이지가 된다  
- 장점:  
  - 모든 메모리 참조에 overhead를 부과하지 않는다  
  - interval rate을 설정할 수 있다  
- 단점:  
  - Scanning all page frames하는 것은 여전히 비효율적일 수 있다. -> 가장 작은거 찾는데 모두 탐색할 수
  - 예: 4GB 메모리에서 4KB 페이지 사용 시 → 백만 개의 페이지 프레임이 존재한다 <br>

![image](https://github.com/user-attachments/assets/1429b9cb-7471-4a2c-b730-7b781b9b50b8)

## 44p

## LRU Approximations: Enhanced Clock Algorithm
- reference bit와 modify bit(dirty bit)를 함께 사용하여 알고리즘을 개선한다  
- 순서쌍 (reference, modify)을 기반으로 다음과 같은 우선순위를 설정한다:  
  1. (0, 0) 최근에 사용되지 않았고 수정되지도 않음(접근X, 수정X) → 교체에 가장 적합한 페이지  
  2. (0, 1) 최근에 사용되지 않았지만 수정됨(접근X, 수정O) → 그다지 좋지는 않지만, 교체 전에 디스크에 써야 함  
  3. (1, 0) 최근에 사용되었고 수정되지 않음(접근O, 수정X) → 아마도 곧 다시 사용될 것  
  4. (1, 1) 최근에 사용되었고 수정되었음(접근O, 수정O) → 아마도 곧 다시 사용될 것이며, 교체 전에 디스크에 써야 함  
- 페이지 교체가 필요할 때, 시계(clock) 알고리즘을 사용하되, 위 네 개의 클래스 중 가장 낮은(좋은) 클래스에서 페이지를 선택하여 교체한다  
  - 비어 있지 않은 가장 낮은 클래스를 찾기 위해 원형 큐(circular queue)를 여러 번 순회할 수 있다 <br>
  -> 여러번 돌아애 할 수도 -> 1번 돌았는데 (0,0)없어서 다시 돌았지만 (0,1)이 없어서 (1,0)을 찾기 위해 또 돈다.

## LRU Approximations: Counting-Based Algorithm
- 각 페이지에 대한 참조 횟수를 세는 counter를 유지한다  
  - 일반적으로는 잘 사용되지 않는다  
- LFU (Least Frequently Used) 알고리즘:  
  - 참조 횟수가 가장 적은 페이지를 교체한다  
- MFU (Most Frequently Used) 알고리즘:  
  - 참조 횟수가 가장 적은 페이지는 최근에 들어온 페이지일 가능성이 높으며, 아직 사용되지 않았을 수도 있다는 가정에 기반하여  
  - 참조 횟수가 가장 많은 페이지를 남기고, 가장 적은 페이지는 남긴다
- 최근 리눅스에서는 MGLRU 알고리즘: <br>
  ![image](https://github.com/user-attachments/assets/f97c77e5-90a6-44eb-88b5-40d9d2def663)

# Page Frame Allocation
## Page Frame Allocation
- 각 process는 최소한의 frames 수를 필요로 한다  
- 최대 프레임 수는 시스템 내 전체 프레임 수이다  
- 그렇다면 각 프로세스에 몇 개의 프레임을 할당할 것인가?
- Two major allocation schemes
  - Fixed allocation vs. Priority allocation
- 또한, 다음 기준에 따라 나눌 수 있다:  
  - Global allocation vs. Local allocation
- Fixed Allocation -> 기준을 고정시킨다.
  - Equal allocation: 모든 프로세스에 동일한 수의 프레임을 할당한다  
  - Proportional allocation: 프로세스의 크기에 비례하여 프레임을 할당한다  
- Priority Allocation
  - 프로세스의 크기 대신 우선순위를 기준으로 비례 할당 방식을 사용한다
- Global Allocation -> 즉, 다른 process가 쓰던 frame을 쓸 수 있다.
  - 프로세스가 시스템의 모든 프레임 중에서 교체할 프레임을 선택한다. <br>
    다른 프로세스의 프레임을 가져올 수 있다  
  - 이 경우, 프로세스의 실행 시간이 크게 달라질 수 있다  
  - 하지만 더 높은 처리량(throughput)을 제공하므로 더 일반적으로 사용된다. -> 시스템 효율 증가.  
- Local Allocation -> process마다 partitioning하자
  - 프로세스가 자신에게 할당된 프레임 집합 내에서만 교체할 프레임을 선택한다  
  - 프로세스별 성능은 더 일관되게 유지된다  
  - 그러나 메모리가 비효율적으로 사용될 수 있다
  - 모든 변인 통제 어려우니 Global Allocation을 쓴다.

# Thrashing
## Thrashing
- 프로세스에 “enough” 페이지(프레임)가 없으면 page-fault rate이 매우 높아진다  
- 페이지를 가져오기 위해 Page fault 발생  
- 기존 프레임을 교체함  
- 그러나 교체된 프레임을 곧 다시 필요로 하게 된다. -> 또 page fault 발생 -> page fault 증가, 유의미한 CPU 감소
- 이로 인해 다음과 같은 현상이 발생한다:  
  - 낮은 CPU utilization  
  - 운영체제가 멀티프로그래밍 수준을 높여야 한다고 판단한다
  - 시스템에 또 다른 프로세스를 추가한다 -> page fault만 증가
- Thrashing
  - process가 busy swapping pages in and out되는 현상이다 <br>

![image](https://github.com/user-attachments/assets/c8354a8a-5835-40ca-b190-c797be538847)
- Demand Paging이 작동하는 이유는 무엇인가? -> Demand Paging이 유효한 이유: locailty때문
  - Locality 모델  
    - 프로세스는 한 locality에서 다른 locality으로 이동한다  
    - 여러 Localities이 겹칠 수도 있다  
- 스래싱이 발생하는 이유는 무엇인가? 
  - $( \Sigma \text{size of locality} > \text{total memory size} \) $ 
    - 지역적 또는 우선순위 기반 페이지 교체를 사용해 영향을 제한할 수 있다  
- 스래싱을 방지하는 방법은?
  - Working-set model  
  - Page-fault frequency

## Working-Set Model
- $\Delta$ ≡ working-set window ≡ 고정된 수의 페이지 참조 <br>
  working-set window -> 최근 이벤트 같은거 기록(기준은 맘대로) -> window로 만든다.
  - 예시: 10,000개의 명령어(동안 접근한 page합 이라고 생각하면 된다.)
- $WSS_i$(프로세스 $P_i$의 워킹셋) =  
  가장 최근 $\Delta$ 동안 참조된 페이지의 총 개수 (시간에 따라 변함)  
  - $\Delta$가 너무 작으면 전체 locality을 포괄하지 못한다 -> 다 담기 힘들다.  
  - $\Delta$가 너무 크면 several localities을 포함하게 된다 -> working set에 너무 많은 정보 포함(불필요한 정보까지)
  - $\Delta = \infty$이면 entire program을 포함하게 된다
- $D = \sum WSS_i$ ≡ total demand frames  
  - locality의 근사치
- D > m  → 스래싱 발생, m은 실제 memory size
- Policy: D > m일 경우, 프로세스 중 하나를 일시 정지하거나 swap out한다 <br>

![image](https://github.com/user-attachments/assets/e745f629-1760-47b5-a2c8-085799b525a7) <br>
![image](https://github.com/user-attachments/assets/fe76bc5e-f889-4c7a-a63b-2a10d6d76b6a) <br>
$\Delta$동안 활성적으로 사용되고 있는 집합을 의미한다. <br>
1번째는 1,2,5,6,7이 활성화, 2번째는 3,4가 활성화된 상태이다

## Working-Set Model (2)
- working set을 추적하는 방법  
  - interval timer와 reference bit를 이용해 근사화한다. -> reference bit를 보면서 한다. 다만, 더 짧게 하고 싶으면 <br>
  (1st ref bit, 2nd ref bit)를 이용한다.
- 예시: $\Delta = 10000$
  - Timer는 매 5,000 타임 유닛마다 interrupts를 발생시킨다
  - 각 page마다 2개의 bits를 메모리에 유지한다 (1st ref bit(첫 번째 참조 비트), (2nd ref bit)두 번째 참조 비트)
  - 페이지가 참조될 때마다 첫 번째 참조 비트를 1로 설정한다
  - 타이머가 인터럽트를 발생시킬 때마다, 첫 번째 참조 비트를 두 번째 참조 비트에 복사하고 첫 번째 비트는 0으로 초기화한다
  - 메모리에 저장된 비트 중 하나라도 1이면 → 해당 페이지는 워킹셋에 포함된 것으로 간주한다
- 이 방식이 완전히 정확하지 않은 이유는?  
  - 참조 시점 간의 순서를 정확히 알 수 없기 때문
- 개선 방안  
  - 10개의 비트를 사용하고 매 1,000 타임 유닛마다 인터럽트를 발생시키는 방식


## Page-Fault Frequency
 • More direct approach than WSS <br>
 -> Page-Fault Frequency를 통해서 좀 더 집적적인 thrasing 판단 가능

## Working Sets and Page Fault Rates
- working set of a process과 page-fault rate 사이에는 Direct relationship가 있다  
- Working set은 시간에 따라 변화한다  
- 시간에 따라 급증(peak)과 급감(valley)이 나타난다 <br>
![image](https://github.com/user-attachments/assets/eba99db5-fbe6-455a-97fa-b194f0aabff2) <br>
- 근본적인 해결책은 더 많은 main memory를 구현하는 것이다

# Allocating Kernel Memory
## Allocating Kernel Memory -> Kernel은 page fault를 야기하지 않는다. -> Kernel은 바로바로 동작 필요
- Kernel memory는 사용자 메모리와 다르게 취급한다  
- 보통은 free-memory pool에서 할당된다. -> 미리 확보, 관리가 핵심이다.
  - Kernel은 다양한 크기의 구조체를 위한 메모리를 요청한다  
  - 일부 Kernel memory는 연속적인 공간이 필요하다  
    - 예: 디바이스 I/O를 위한 메모리  
- allocate kernel memory을 위한 대표적인 방법  
  - Buddy system allocator
  - Slab allocator

## Buddy System Allocator
- 고정 크기의 물리적으로 연속된 페이지 세그먼트에서 메모리를 할당한다  
- 2의 제곱 기반 할당자(power-of-2 allocator)를 사용해 메모리를 할당한다  
  - 요청 크기를 2의 거듭제곱 단위로 맞춘다  
  - 요청은 가장 가까운 더 큰 2의 거듭제곱으로 반올림된다. -> 40은 $2^6$으로
  - 현재 사용 가능한 블록보다 작은 크기가 필요한 경우 해당 블록을 두 개의 buddy로 분할(chunk)
    - 이 과정을 적절한 크기의 블록이 나올 때까지 반복한다  
- 장점: 사용하지 않는 블록을 빠르게 병합하여 큰 블록으로 만들 수 있다  
- 단점: fragmentation이 발생한다. -> internal fragmentation이 심하다. 40을 $2^6$으로 24낭비 <br>

![image](https://github.com/user-attachments/assets/5d94abb1-a776-410e-be67-354a622519e5)

## Slab Allocator
- 슬랩(slab)은 하나 이상의 물리적으로 연속된 페이지로 구성된다. -> page묶음
- Cache는 하나 이상의 슬랩으로 이루어진다  
- 고유한 kernel data structure마다 하나의 캐시가 존재한다. -> kernel data structure마다 공간 분리
  - 각 cache는 데이터 구조체의 인스턴스인 객체들로 채워진다
```
이 부분은 수업에서 안나감 
- 캐시가 생성될 때, 객체들은 free 상태로 표시되어 채워진다  
- 구조체가 저장되면, 해당 객체들은 사용 중(used)으로 표시된다  
- 슬랩이 사용 중인 객체들로 가득 차면, 다음 객체는 빈(empty) 슬랩에서 할당된다  
  - 빈 슬랩이 없으면, 새로운 슬랩이 할당된다
```
- 장점은 fragmentation이 없고, 빠른 메모리 요청 처리가 가능하다는 점이다 <br>

![image](https://github.com/user-attachments/assets/5348c6e6-2575-4846-bc7e-12246abf5a93)
